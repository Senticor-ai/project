import { Meta } from "@storybook/addon-docs/blocks";

<Meta title="Product/Epics/Copilot V2+" />

# Epic: Copilot V2+ — Multi-turn, Streaming & Infrastructure

**Status:** Not started
**Priority:** Future (after V1 ships)
**Depends on:** [Copilot V1](?path=/docs/product-epics-copilot-v1--docs)
**See also:** [Schema Enrichment](?path=/docs/product-epics-schema-org-type-enrichment--docs) (richer item types for Copilot suggestions)

## Context

V1 delivers a single-message chat flow: user message → FastAPI proxy → Haystack agent → OpenRouter → tool calls → response. Three tools, German system prompt, graceful 503/502 handling. No conversation memory, no streaming, no awareness of the user's existing items.

This epic collects everything deferred from V1 that makes Copilot a production-grade conversational assistant.

---

## Deferred Work Items

### 1. Conversation History / Multi-turn Context

V1 is stateless — each message is independent. V2 introduces server-side conversation history so Copilot can reference prior messages, follow up on suggestions, and maintain coherent multi-turn dialogue.

- Store conversation turns in the chat completions request
- Manage context window budget (token counting, summarization)
- Clear/reset conversation action in UI

### 2. User Items in Prompt Context

Copilot V1 cannot see what the user already has. V2 injects relevant items (inbox, projects, next actions) into the system prompt so Copilot can make context-aware suggestions — e.g. linking a new action to an existing project.

- RAG or direct injection strategy (evaluate token budget)
- Privacy boundary: only inject items belonging to the current user
- Refresh strategy when items change mid-conversation

### 3. Streaming (Server-Sent Events)

V1 waits for the full response before displaying. V2 streams tokens as they arrive for a responsive feel.

- Backend: SSE endpoint (`text/event-stream`) wrapping OpenRouter streaming
- Frontend: `EventSource` or `fetch` with `ReadableStream` in `useTayApi`
- Incremental rendering in `TayMessageBubble`
- Tool call accumulation during stream (partial JSON assembly)

### 4. Model Fallback

V1 uses a single configured model. V2 supports a comma-separated model list in `OPENROUTER_MODEL` and retries with the next model on failure.

- Parse model list from env var
- Retry logic with exponential backoff
- Log which model ultimately served each request
- Surface model info in telemetry (OpenTelemetry span attributes)

### 5. K8s Deployment Manifest for Agents

V1 runs the agent in the existing FastAPI process. V2 separates agent workloads for independent scaling.

- Dedicated Deployment / Service for the agent worker
- Resource limits and HPA configuration
- Health checks and readiness probes
- Network policy for agent ↔ API ↔ OpenRouter traffic

### 6. CI Pipeline Jobs for Agents

Add CI stages that validate agent-related code (for the GitHub repository pipeline).

- Lint and type-check agent modules (`ruff`, `mypy`)
- Unit tests for Haystack pipeline and tool implementations
- Integration test: mock OpenRouter, verify tool call round-trip
- Smoke test against staging OpenRouter (gated, manual trigger)

### 7. DB Persistence for Conversations

V1 conversations are ephemeral (frontend state only). V2 persists conversations in PostgreSQL so users can resume or review past chats.

- `conversations` table: `id`, `user_id`, `created_at`, `updated_at`, `archived_at`
- `conversation_messages` table: `id`, `conversation_id`, `role`, `content`, `tool_calls`, `created_at`
- API: `GET /conversations`, `GET /conversations/:id/messages`, `POST /conversations/:id/messages`
- Frontend: conversation list, resume, archive (no delete per data retention policy)

---

## Dependencies & Sequencing

| Item                 | Depends on         | Notes                                           |
| -------------------- | ------------------ | ----------------------------------------------- |
| Multi-turn context   | DB persistence     | Need stored history to build prompt             |
| User items in prompt | Multi-turn context | Context injection extends prompt assembly       |
| Streaming            | Independent        | Can ship before or after multi-turn             |
| Model fallback       | Independent        | Pure backend, no frontend changes               |
| K8s manifest         | Independent        | Infra work, can parallel with features          |
| CI pipeline          | K8s manifest       | Test jobs should match deployment topology      |
| DB persistence       | Independent        | Foundation for multi-turn and conversation list |

**Suggested order:** DB persistence → multi-turn → user items → streaming. Model fallback and infra items can be done in parallel.

---

## Verification

```bash
# Backend
cd backend && uv run ruff check .
cd backend && uv run mypy app/
cd backend && uv run python -m pytest

# Frontend
cd frontend && npx tsc -b --noEmit
cd frontend && CI=1 npx vitest run --project=unit
cd frontend && npx storybook build
```
