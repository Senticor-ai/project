import { Meta } from "@storybook/addon-docs/blocks";

<Meta title="Engineering/Backend API Requests: Import UX" />

# Import UX: Architecture & Adoption Guide

This page documents the end-to-end import flow as currently implemented (Native and Nirvana).

> For the import system architecture and how to add a new importer, see [Import Architecture](?path=/docs/engineering-import-architecture--docs).

---

## Current Implementation: Nirvana Import

### UX Flow

The import follows a five-step dialog: **select → uploading → preview → importing → results**.

| Step          | User sees                                                                  | What happens                                                                      |
| ------------- | -------------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| **select**    | File drop zone                                                             | User picks a `.json` file                                                         |
| **uploading** | Spinner, "Uploading file..."                                               | Chunked upload via `FilesApi`, then `ImportsApi.inspectNirvana()`                 |
| **preview**   | Item count, bucket breakdown, "Include completed" toggle                   | User reviews and clicks "Import N items"                                          |
| **importing** | Spinner, "Importing...", job status text                                   | `ImportsApi.importNirvanaFromFile()` starts a background job; hook polls every 2s |
| **results**   | Success/error icon, created/updated/skipped/errors stats, bucket breakdown | User can click a bucket to navigate or close                                      |

### Architecture Layers

```
┌───────────────────────────────────────────────────┐
│  {Source}ImportDialog.tsx   (thin wrapper)         │
│  └── ImportDialog.tsx      (shared 5-step UI)     │
│      └── useImportSource(config)  (shared hook)   │
│          ├── useFileUpload()   (chunked upload)   │
│          ├── useMutation: inspect (config.inspectFn)
│          ├── useMutation: startImport (config.importFn)
│          └── useQuery: job polling                │
├───────────────────────────────────────────────────┤
│  api-client.ts                                    │
│  ├── FilesApi   (initiate / uploadChunk /         │
│  │               complete)                        │
│  └── ImportsApi (inspect{Source} /                │
│                   import{Source}FromFile /         │
│                   getJob)                         │
├───────────────────────────────────────────────────┤
│  Backend (FastAPI)                                │
│  ├── POST /files/initiate                         │
│  ├── PUT  /files/upload/{upload_id}               │
│  ├── POST /files/complete                         │
│  ├── POST /imports/{source}/inspect               │
│  ├── POST /imports/{source}/from-file             │
│  └── GET  /imports/jobs/{job_id}                  │
└───────────────────────────────────────────────────┘
```

> See [Import Architecture](?path=/docs/engineering-import-architecture--docs) for the full file structure, `ImportSourceConfig` contract, and checklist for adding new importers.

### Key Implementation Details

**Chunked file upload** (`use-file-upload.ts`):

1. `FilesApi.initiate(filename, contentType, totalSize)` — returns `upload_id`, `chunk_size`, `chunk_total`
2. Loop: `FilesApi.uploadChunk(uploadId, chunk, index, total)` — sends each chunk with `X-Chunk-Index` / `X-Chunk-Total` headers
3. `FilesApi.complete(uploadId)` — finalizes upload, returns `FileRecord` with `file_id` and `sha256`

**Inspect before import** (`ImportsApi.inspectNirvana`):

- Dry-run that returns a `ImportSummary`: `total`, `created`, `updated`, `skipped`, `errors`, `bucket_counts`, `sample_errors`
- The dialog calls inspect after upload completes, then again if the user toggles "Include completed"
- Lets users see exactly what will happen before committing

**Background job with polling** (`use-nirvana-import.ts`):

- `startImport` mutation → backend returns `ImportJobResponse` with `job_id` and `status: "queued"`
- `useQuery` polls `GET /imports/jobs/{job_id}` every **2 seconds** while status is `"queued"` or `"running"`
- Polling stops automatically when status changes to `"completed"` or `"failed"`
- During `"running"`, the hook invalidates the items query cache every **3 seconds** so imported items appear incrementally in the list behind the dialog
- A `hasCompletedInvalidation` ref guard ensures the final cache invalidation fires exactly once

**Error handling**:

- Upload failure → dialog resets to "select" step, shows `upload.error.message`
- Inspect failure → dialog resets to "select" step
- Import start failure → dialog resets to "preview" step
- Job failure → results step shows error icon + `jobData.error` message + `sample_errors`
- The `ApiError` class carries `status`, `message`, and `details` from the backend response

### API Types

```typescript
// Request to start a Nirvana import
type NirvanaImportFromFileRequest = {
  file_id: string;
  source?: string;
  update_existing?: boolean;
  include_completed?: boolean;
  emit_events?: boolean;
  state_bucket_map?: Record<string, string>;
  default_bucket?: string;
};

// Summary returned by inspect and attached to completed jobs
type ImportSummary = {
  total: number;
  created: number;
  updated: number;
  skipped: number;
  errors: number;
  bucket_counts: Record<string, number>;
  sample_errors: string[];
};

// Job status (polling response)
type ImportJobResponse = {
  job_id: string;
  status: string; // "queued" | "running" | "completed" | "failed"
  file_id: string;
  source: string;
  created_at: string;
  updated_at: string;
  started_at: string | null;
  finished_at: string | null;
  summary: ImportSummary | null; // populated on completion
  error: string | null; // populated on failure
};
```

### Current Limitations

- **No progress bar**: The backend job response lacks `processed_count` / `total_count`, so the "importing" step can only show a spinner with the job status string, not a percentage
- **No duration display**: `started_at` and `finished_at` are available but no computed `duration_ms` is returned — frontend could compute this itself from the two timestamps if desired
- **Polling, not push**: Import progress relies on 2s polling; no Server-Sent Events yet

---

## Backend Improvement Requests

The following backend changes would improve the import UX but are **not yet implemented**:

### Import Progress Reporting

Add `processed_count` and `total_count` to `ImportJobResponse` so the frontend can show a progress bar instead of an indeterminate spinner. The worker should update `processed_count` periodically (e.g., every 500 items). The frontend already polls every 2s and would pick up changes automatically.

### Bucket Counts Endpoint

A `GET /items/counts` endpoint returning `Record<string, number>` would let `BucketNav` show sidebar counts without fetching all items. Currently the frontend loads all items and counts client-side.

### Server-Side Bucket Filtering

Adding `?bucket=` and `?type=` params to `GET /items/sync` would avoid loading 20K items when the user only needs the 86 in their inbox.

### Server-Sent Events

An SSE endpoint (`GET /items/events`) with `item_upserted`, `item_archived`, `import_progress`, and `import_completed` events would replace polling entirely and enable real-time multi-user sync.

---

## JSON-LD Payload Schemas

The exact JSON-LD shapes accepted by `POST /items` and `PATCH /items/{id}` are available as machine-readable JSON Schema via the backend API:

| Endpoint              | Description                                        |
| --------------------- | -------------------------------------------------- |
| `GET /schemas`        | List available schema names                        |
| `GET /schemas/{name}` | Download a JSON Schema (`application/schema+json`) |

Available schemas: `inbox-item`, `action-item`, `project-item`, `reference-item`, `item-patch`, `property-value`.

These are generated at runtime from the backend Pydantic models — the API is the single source of truth. Frontend tests can fetch schemas directly from the API for validation.
